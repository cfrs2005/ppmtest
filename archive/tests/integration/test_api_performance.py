"""
APIæ€§èƒ½æµ‹è¯•è„šæœ¬
"""

import time
import requests
import statistics
import concurrent.futures
from datetime import datetime

class APIPerformanceTester:
    """APIæ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self, base_url="http://localhost:5000"):
        self.base_url = base_url
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Bilibili-Analyzer-Performance-Test/1.0'
        })
    
    def test_endpoint_performance(self, method, endpoint, data=None, params=None, iterations=10):
        """æµ‹è¯•å•ä¸ªç«¯ç‚¹çš„æ€§èƒ½"""
        url = f"{self.base_url}{endpoint}"
        response_times = []
        success_count = 0
        error_count = 0
        
        print(f"\nğŸ”¬ æµ‹è¯• {method} {endpoint} ({iterations} æ¬¡è¯·æ±‚)")
        
        for i in range(iterations):
            try:
                start_time = time.time()
                
                if method.upper() == 'GET':
                    response = self.session.get(url, params=params, timeout=10)
                elif method.upper() == 'POST':
                    response = self.session.post(url, json=data, timeout=10)
                else:
                    print(f"ä¸æ”¯æŒçš„HTTPæ–¹æ³•: {method}")
                    continue
                
                end_time = time.time()
                response_time = end_time - start_time
                response_times.append(response_time)
                
                if response.status_code < 400:
                    success_count += 1
                else:
                    error_count += 1
                
                print(f"  è¯·æ±‚ {i+1}: {response_time:.3f}s (çŠ¶æ€ç : {response.status_code})")
                
            except requests.exceptions.RequestException as e:
                error_count += 1
                print(f"  è¯·æ±‚ {i+1}: å¤±è´¥ - {e}")
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if response_times:
            avg_time = statistics.mean(response_times)
            median_time = statistics.median(response_times)
            min_time = min(response_times)
            max_time = max(response_times)
            std_dev = statistics.stdev(response_times) if len(response_times) > 1 else 0
            
            print(f"  ğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
            print(f"    å¹³å‡å“åº”æ—¶é—´: {avg_time:.3f}s")
            print(f"    ä¸­ä½æ•°å“åº”æ—¶é—´: {median_time:.3f}s")
            print(f"    æœ€å°å“åº”æ—¶é—´: {min_time:.3f}s")
            print(f"    æœ€å¤§å“åº”æ—¶é—´: {max_time:.3f}s")
            print(f"    æ ‡å‡†å·®: {std_dev:.3f}s")
            print(f"    æˆåŠŸç‡: {success_count/iterations*100:.1f}%")
            
            # æ€§èƒ½è¯„çº§
            if avg_time < 0.1:
                grade = "ğŸŸ¢ ä¼˜ç§€"
            elif avg_time < 0.5:
                grade = "ğŸŸ¡ è‰¯å¥½"
            elif avg_time < 1.0:
                grade = "ğŸŸ  ä¸€èˆ¬"
            else:
                grade = "ğŸ”´ è¾ƒå·®"
            
            print(f"    æ€§èƒ½è¯„çº§: {grade}")
            
            return {
                'endpoint': endpoint,
                'method': method,
                'avg_time': avg_time,
                'median_time': median_time,
                'min_time': min_time,
                'max_time': max_time,
                'std_dev': std_dev,
                'success_rate': success_count/iterations,
                'total_requests': iterations,
                'success_count': success_count,
                'error_count': error_count
            }
        else:
            print(f"  âŒ æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥äº†")
            return None
    
    def test_concurrent_performance(self, method, endpoint, data=None, params=None, concurrent_users=5, requests_per_user=10):
        """æµ‹è¯•å¹¶å‘æ€§èƒ½"""
        url = f"{self.base_url}{endpoint}"
        response_times = []
        success_count = 0
        error_count = 0
        
        print(f"\nğŸš€ å¹¶å‘æµ‹è¯• {method} {endpoint} ({concurrent_users} ç”¨æˆ·, æ¯ç”¨æˆ· {requests_per_user} è¯·æ±‚)")
        
        def make_requests():
            """å‘é€è¯·æ±‚çš„å‡½æ•°"""
            nonlocal response_times, success_count, error_count
            
            for i in range(requests_per_user):
                try:
                    start_time = time.time()
                    
                    if method.upper() == 'GET':
                        response = self.session.get(url, params=params, timeout=30)
                    elif method.upper() == 'POST':
                        response = self.session.post(url, json=data, timeout=30)
                    else:
                        continue
                    
                    end_time = time.time()
                    response_time = end_time - start_time
                    
                    response_times.append(response_time)
                    
                    if response.status_code < 400:
                        success_count += 1
                    else:
                        error_count += 1
                    
                    # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
                    time.sleep(0.1 + (i % 3) * 0.1)
                    
                except requests.exceptions.RequestException as e:
                    error_count += 1
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ¨¡æ‹Ÿå¹¶å‘ç”¨æˆ·
        start_time = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = [executor.submit(make_requests) for _ in range(concurrent_users)]
            concurrent.futures.wait(futures)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if response_times:
            avg_time = statistics.mean(response_times)
            median_time = statistics.median(response_times)
            min_time = min(response_times)
            max_time = max(response_times)
            std_dev = statistics.stdev(response_times) if len(response_times) > 1 else 0
            
            total_requests = concurrent_users * requests_per_user
            requests_per_second = total_requests / total_time if total_time > 0 else 0
            
            print(f"  ğŸ“Š å¹¶å‘æ€§èƒ½ç»Ÿè®¡:")
            print(f"    æ€»è€—æ—¶: {total_time:.3f}s")
            print(f"    å¹³å‡å“åº”æ—¶é—´: {avg_time:.3f}s")
            print(f"    ä¸­ä½æ•°å“åº”æ—¶é—´: {median_time:.3f}s")
            print(f"    æœ€å°å“åº”æ—¶é—´: {min_time:.3f}s")
            print(f"    æœ€å¤§å“åº”æ—¶é—´: {max_time:.3f}s")
            print(f"    æ ‡å‡†å·®: {std_dev:.3f}s")
            print(f"    æˆåŠŸç‡: {success_count/total_requests*100:.1f}%")
            print(f"    è¯·æ±‚æ•°/ç§’: {requests_per_second:.1f}")
            
            # å¹¶å‘æ€§èƒ½è¯„çº§
            if requests_per_second > 50:
                grade = "ğŸŸ¢ ä¼˜ç§€"
            elif requests_per_second > 20:
                grade = "ğŸŸ¡ è‰¯å¥½"
            elif requests_per_second > 10:
                grade = "ğŸŸ  ä¸€èˆ¬"
            else:
                grade = "ğŸ”´ è¾ƒå·®"
            
            print(f"    å¹¶å‘æ€§èƒ½è¯„çº§: {grade}")
            
            return {
                'endpoint': endpoint,
                'method': method,
                'concurrent_users': concurrent_users,
                'requests_per_user': requests_per_user,
                'total_time': total_time,
                'avg_time': avg_time,
                'median_time': median_time,
                'min_time': min_time,
                'max_time': max_time,
                'std_dev': std_dev,
                'success_rate': success_count/total_requests,
                'requests_per_second': requests_per_second,
                'total_requests': total_requests,
                'success_count': success_count,
                'error_count': error_count
            }
        else:
            print(f"  âŒ æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥äº†")
            return None
    
    def run_comprehensive_performance_test(self):
        """è¿è¡Œå…¨é¢çš„æ€§èƒ½æµ‹è¯•"""
        print("ğŸ¯ å¼€å§‹å…¨é¢çš„APIæ€§èƒ½æµ‹è¯•")
        print("=" * 60)
        print(f"æµ‹è¯•æ—¶é—´: {datetime.now().isoformat()}")
        print(f"æµ‹è¯•ç›®æ ‡: {self.base_url}")
        print("=" * 60)
        
        results = []
        
        # åŸºç¡€ç«¯ç‚¹æ€§èƒ½æµ‹è¯•
        basic_endpoints = [
            ('GET', '/api/v1/health'),
            ('GET', '/api/v1/ping'),
            ('GET', '/api/v1/info'),
            ('GET', '/api/v1/stats'),
        ]
        
        print("\nğŸ“‹ åŸºç¡€ç«¯ç‚¹æ€§èƒ½æµ‹è¯•")
        print("-" * 30)
        
        for method, endpoint in basic_endpoints:
            result = self.test_endpoint_performance(method, endpoint, iterations=20)
            if result:
                results.append(result)
        
        # åªè¯»ç«¯ç‚¹æ€§èƒ½æµ‹è¯•
        readonly_endpoints = [
            ('GET', '/api/v1/videos'),
            ('GET', '/api/v1/tags'),
            ('GET', '/api/v1/knowledge'),
            ('GET', '/api/v1/knowledge/search', None, {'q': 'test'}),
        ]
        
        print("\nğŸ“– åªè¯»ç«¯ç‚¹æ€§èƒ½æµ‹è¯•")
        print("-" * 30)
        
        for method, endpoint, *args in readonly_endpoints:
            params = args[0] if args else None
            result = self.test_endpoint_performance(method, endpoint, params=params, iterations=10)
            if result:
                results.append(result)
        
        # å¹¶å‘æ€§èƒ½æµ‹è¯•
        print("\nğŸš€ å¹¶å‘æ€§èƒ½æµ‹è¯•")
        print("-" * 30)
        
        concurrent_endpoints = [
            ('GET', '/api/v1/health'),
            ('GET', '/api/v1/stats'),
        ]
        
        for method, endpoint in concurrent_endpoints:
            result = self.test_concurrent_performance(method, endpoint, concurrent_users=10, requests_per_user=5)
            if result:
                results.append(result)
        
        # ç”ŸæˆæŠ¥å‘Š
        print("\n" + "=" * 60)
        print("ğŸ“Š æ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
        print("=" * 60)
        
        # æŒ‰æ€§èƒ½æ’åº
        sorted_results = sorted(results, key=lambda x: x.get('avg_time', float('inf')))
        
        print("\nğŸ† æ€§èƒ½æ’è¡Œæ¦œ (æŒ‰å¹³å‡å“åº”æ—¶é—´)")
        print("-" * 50)
        for i, result in enumerate(sorted_results[:10], 1):
            print(f"{i:2d}. {result['method']} {result['endpoint']}")
            print(f"    å¹³å‡å“åº”æ—¶é—´: {result['avg_time']:.3f}s")
            print(f"    æˆåŠŸç‡: {result['success_rate']*100:.1f}%")
            print()
        
        # æ€§èƒ½ç»Ÿè®¡
        if results:
            avg_times = [r['avg_time'] for r in results if 'avg_time' in r]
            success_rates = [r['success_rate'] for r in results if 'success_rate' in r]
            
            print("ğŸ“ˆ æ€»ä½“æ€§èƒ½ç»Ÿè®¡")
            print("-" * 30)
            print(f"æµ‹è¯•ç«¯ç‚¹æ•°é‡: {len(results)}")
            print(f"å¹³å‡å“åº”æ—¶é—´: {statistics.mean(avg_times):.3f}s")
            print(f"å¹³å‡æˆåŠŸç‡: {statistics.mean(success_rates)*100:.1f}%")
            print(f"æœ€å¿«å“åº”æ—¶é—´: {min(avg_times):.3f}s")
            print(f"æœ€æ…¢å“åº”æ—¶é—´: {max(avg_times):.3f}s")
            
            # æ€§èƒ½å»ºè®®
            print("\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®")
            print("-" * 30)
            
            slow_endpoints = [r for r in results if r.get('avg_time', 0) > 0.5]
            if slow_endpoints:
                print("ğŸŒ ä»¥ä¸‹ç«¯ç‚¹å“åº”è¾ƒæ…¢ï¼Œå»ºè®®ä¼˜åŒ–:")
                for result in slow_endpoints:
                    print(f"   - {result['method']} {result['endpoint']}: {result['avg_time']:.3f}s")
            
            low_success_endpoints = [r for r in results if r.get('success_rate', 0) < 0.95]
            if low_success_endpoints:
                print("âš ï¸  ä»¥ä¸‹ç«¯ç‚¹æˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥:")
                for result in low_success_endpoints:
                    print(f"   - {result['method']} {result['endpoint']}: {result['success_rate']*100:.1f}%")
            
            if not slow_endpoints and not low_success_endpoints:
                print("âœ… æ‰€æœ‰ç«¯ç‚¹æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼")
        
        return results

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # è·å–åŸºç¡€URL
    base_url = sys.argv[1] if len(sys.argv) > 1 else "http://localhost:5000"
    
    # åˆ›å»ºæ€§èƒ½æµ‹è¯•å™¨
    tester = APIPerformanceTester(base_url)
    
    # è¿è¡Œæ€§èƒ½æµ‹è¯•
    results = tester.run_comprehensive_performance_test()
    
    # è¾“å‡ºç»“æœ
    print(f"\nğŸ‰ æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    import json
    filename = f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“Š æµ‹è¯•äº† {len(results)} ä¸ªç«¯ç‚¹")
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç«¯ç‚¹éƒ½è¾¾åˆ°äº†æ€§èƒ½è¦æ±‚
    all_good = True
    for result in results:
        if result.get('avg_time', 0) > 1.0 or result.get('success_rate', 0) < 0.9:
            all_good = False
            break
    
    if all_good:
        print("âœ… æ‰€æœ‰ç«¯ç‚¹éƒ½è¾¾åˆ°äº†æ€§èƒ½è¦æ±‚ï¼")
        sys.exit(0)
    else:
        print("âš ï¸  éƒ¨åˆ†ç«¯ç‚¹æœªè¾¾åˆ°æ€§èƒ½è¦æ±‚ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š")
        sys.exit(1)

if __name__ == "__main__":
    main()